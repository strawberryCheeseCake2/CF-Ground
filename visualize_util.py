import os
import numpy as np
from PIL import Image, ImageFont, ImageDraw
import torch
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import matplotlib.patheffects as pe
from matplotlib.lines import Line2D
from pathlib import Path
from qwen_vl_utils import process_vision_info


@torch.inference_mode()
def get_attn_map(image: Image.Image, attn_scores: list, n_width: int, n_height: int) -> Image.Image:
    """
    ì£¼ì–´ì§„ ì´ë¯¸ì§€ ìœ„ì— ì–´í…ì…˜ ìŠ¤ì½”ì–´ë¡œ íˆíŠ¸ë§µì„ ìƒì„±í•˜ì—¬ ê²¹ì¹©ë‹ˆë‹¤.

    Args:
        image (Image.Image): ì›ë³¸ PIL ì´ë¯¸ì§€.
        attn_scores (list): 1ì°¨ì›ìœ¼ë¡œ í¼ì³ì§„ ì–´í…ì…˜ ìŠ¤ì½”ì–´ ë¦¬ìŠ¤íŠ¸.
        n_width (int): ì–´í…ì…˜ ë§µì˜ ë„ˆë¹„ (íŒ¨ì¹˜ ê°œìˆ˜).
        n_height (int): ì–´í…ì…˜ ë§µì˜ ë†’ì´ (íŒ¨ì¹˜ ê°œìˆ˜).

    Returns:
        Image.Image: íˆíŠ¸ë§µì´ ê²¹ì³ì§„ PIL ì´ë¯¸ì§€.
    """
    w, h = image.size
    # 1ì°¨ì› ìŠ¤ì½”ì–´ë¥¼ 2ì°¨ì› ë°°ì—´ë¡œ ë³€í™˜
    scores = np.array(attn_scores).reshape(n_height, n_width)

    # ìŠ¤ì½”ì–´ë¥¼ 0~1 ì‚¬ì´ë¡œ ì •ê·œí™”
    min_val, max_val = scores.min(), scores.max()
    denom = (max_val - min_val) if (max_val - min_val) != 0 else 1.0
    scores_norm = (scores - min_val) / denom

    # ì •ê·œí™”ëœ ìŠ¤ì½”ì–´ë¥¼ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ì— ë§ê²Œ ë¦¬ì‚¬ì´ì¦ˆí•˜ì—¬ í‘ë°± ë§µ ìƒì„±
    score_map = Image.fromarray((scores_norm * 255).astype(np.uint8)).resize(
        (w, h), resample=Image.NEAREST
    )
    
    # Matplotlibì˜ 'jet' ì»¬ëŸ¬ë§µì„ ì‚¬ìš©í•˜ì—¬ í‘ë°± ë§µì„ ì»¬ëŸ¬ íˆíŠ¸ë§µìœ¼ë¡œ ë³€í™˜
    colormap = plt.get_cmap('jet')
    colored_score_map_array = colormap(np.array(score_map) / 255.0)[:, :, :3]
    colored_overlay = Image.fromarray((colored_score_map_array * 255).astype(np.uint8))
    
    # ì›ë³¸ ì´ë¯¸ì§€ì™€ íˆíŠ¸ë§µì„ íˆ¬ëª…ë„(alpha)ë¥¼ ì¡°ì ˆí•˜ì—¬ í•©ì„±
    blended_image = Image.blend(image.convert('RGB'), colored_overlay, alpha=0.4)
    
    return blended_image


@torch.inference_mode()
def draw_point(image: Image.Image, point: tuple, radius=10, color=(255, 0, 0)) -> Image.Image:
    """
    ì´ë¯¸ì§€ ìœ„ì˜ íŠ¹ì • ì¢Œí‘œì— ì›ì„ ê·¸ë¦½ë‹ˆë‹¤.

    Args:
        image (Image.Image): PIL ì´ë¯¸ì§€.
        point (tuple): (x, y) ì¢Œí‘œ (0~1 ì‚¬ì´ì˜ ì •ê·œí™”ëœ ê°’).
        radius (int): ì›ì˜ ë°˜ì§€ë¦„.
        color (tuple): ì›ì˜ ìƒ‰ìƒ (R, G, B).

    Returns:
        Image.Image: ì›ì´ ê·¸ë ¤ì§„ PIL ì´ë¯¸ì§€.
    """
    w, h = image.size
    # ì •ê·œí™”ëœ ì¢Œí‘œë¥¼ ì‹¤ì œ í”½ì…€ ì¢Œí‘œë¡œ ë³€í™˜
    abs_x, abs_y = int(point[0] * w), int(point[1] * h)

    draw = ImageDraw.Draw(image)
    # ì›ì˜ ì™¸ê³½ì„  ê·¸ë¦¬ê¸°
    draw.ellipse(
        [(abs_x - radius, abs_y - radius), (abs_x + radius, abs_y + radius)],
        outline=color,
        width=3  # ì„  ë‘ê»˜
    )
    return image

# -----------------------------------------
# ë©”ì¸ ì‹œê°í™” í•¨ìˆ˜
# -----------------------------------------


@torch.inference_mode()
def draw_top_patch_attentions(image: Image.Image, attn_scores: np.ndarray, n_width: int, n_height: int, top_k: int = 3) -> Image.Image:
    """
    ì–´í…ì…˜ ìŠ¤ì½”ì–´ê°€ ê°€ì¥ ë†’ì€ Top-K íŒ¨ì¹˜ì˜ ì¤‘ì‹¬ì— í•´ë‹¹ ìŠ¤ì½”ì–´ ê°’ì„ í…ìŠ¤íŠ¸ë¡œ ê·¸ë¦½ë‹ˆë‹¤.
    """
    img_w, img_h = image.size
    patch_pixel_w = img_w / n_width
    patch_pixel_h = img_h / n_height

    # ì–´í…ì…˜ ìŠ¤ì½”ì–´ê°€ ë†’ì€ ìˆœì„œëŒ€ë¡œ ì¸ë±ìŠ¤ë¥¼ ì •ë ¬
    # np.argsort()ëŠ” ì˜¤ë¦„ì°¨ìˆœì´ë¯€ë¡œ ë’¤ì§‘ì–´ì¤Œ `[::-1]`
    top_indices = np.argsort(attn_scores)[::-1][:top_k]

    draw = ImageDraw.Draw(image)
    try:
        # í°íŠ¸ ë¡œë“œ (ì—†ì„ ê²½ìš° ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©)
        font = ImageFont.truetype("arial.ttf", 15)
    except IOError:
        font = ImageFont.load_default()

    for idx in top_indices:
        # 1ì°¨ì› ì¸ë±ìŠ¤ë¥¼ 2ì°¨ì› íŒ¨ì¹˜ ì¢Œí‘œë¡œ ë³€í™˜
        patch_y = idx // n_width
        patch_x = idx % n_width
        
        # íŒ¨ì¹˜ì˜ ì¤‘ì‹¬ í”½ì…€ ì¢Œí‘œ ê³„ì‚°
        center_x = (patch_x + 0.5) * patch_pixel_w
        center_y = (patch_y + 0.5) * patch_pixel_h
        
        # ì–´í…ì…˜ ê°’ í…ìŠ¤íŠ¸ ì¤€ë¹„
        score_val = attn_scores[idx]
        text = f"{score_val:.3f}"
        
        # í…ìŠ¤íŠ¸ ë°°ê²½ ë° ìœ„ì¹˜ ê³„ì‚°
        text_bbox = draw.textbbox((0, 0), text, font=font)
        text_w = text_bbox[2] - text_bbox[0]
        text_h = text_bbox[3] - text_bbox[1]
        text_bg_rect = [
            (center_x - text_w / 2 - 2, center_y - text_h / 2 - 2), # ì¢Œìƒë‹¨
            (center_x + text_w / 2 + 2, center_y + text_h / 2 + 2)  # ìš°í•˜ë‹¨
        ]
        
        # í…ìŠ¤íŠ¸ ë°°ê²½(í°ìƒ‰ ì‚¬ê°í˜•)ê³¼ í…ìŠ¤íŠ¸(ê²€ì€ìƒ‰) ê·¸ë¦¬ê¸°
        draw.rectangle(text_bg_rect, fill="white")
        draw.text(
            (center_x - text_w / 2, center_y - text_h / 2),
            text,
            fill="black",
            font=font
        )
        
    return image


def visualize_results(crop_list: list, prediction_results: dict, instruction: str, save_path: str):
    """
    ì¶”ë¡  ê²°ê³¼ë¥¼ ë°›ì•„ ì–´í…ì…˜ ë§µ, Top-3 ì–´í…ì…˜ ê°’, Top-1 ì˜ˆì¸¡ ì§€ì , ê·¸ë¦¬ê³ 
    ê° ì´ë¯¸ì§€ì˜ ì–´í…ì…˜ ì´í•©ì„ ì‹œê°í™”í•©ë‹ˆë‹¤.
    """
    per_image_outputs = prediction_results.get('per_image', [])
    
    if not per_image_outputs:
        print("ì‹œê°í™”í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    num_images = len(per_image_outputs)
    fig, axes = plt.subplots(1, num_images, figsize=(8 * num_images, 8))
    if num_images == 1:
        axes = [axes]
        
    fig.suptitle(f"Instruction: {instruction}", fontsize=16)

    for result in per_image_outputs:
        idx = result['index']
        # original_image = original_images[idx]
        original_image = crop_list[idx]['resized_img']
        
        # 1. ì–´í…ì…˜ ë§µ ìƒì„±
        blended_img = get_attn_map(
            image=original_image,
            attn_scores=result['attn_scores'][0],
            n_width=result['n_width'],
            n_height=result['n_height']
        )
        
        # 2. Top-3 ì–´í…ì…˜ ê°’ í…ìŠ¤íŠ¸ë¡œ ê·¸ë¦¬ê¸°
        attn_scores_np = np.array(result['attn_scores'][0])
        img_with_attns = draw_top_patch_attentions(
            blended_img,
            attn_scores_np,
            result['n_width'],
            result['n_height'],
            top_k=3
        )
        
        # 3. Top-1 ì˜ˆì¸¡ ì§€ì  ê·¸ë¦¬ê¸°
        if result['topk_points']:
            top_point = result['topk_points'][0]
            final_img = draw_point(img_with_attns, top_point, color=(0, 255, 0)) # ì´ˆë¡ìƒ‰ ì›
        else:
            final_img = img_with_attns

        # ì–´í…ì…˜ ìŠ¤ì½”ì–´ ì´í•© ê³„ì‚°
        total_attention_score = np.sum(attn_scores_np)
            
        # 4. ê²°ê³¼ ì´ë¯¸ì§€ í‘œì‹œ
        ax = axes[idx]
        ax.imshow(final_img)
        # ì œëª©ì— ì´ë¯¸ì§€ ë²ˆí˜¸ì™€ ì–´í…ì…˜ ì´í•©ì„ í•¨ê»˜ í‘œì‹œ
        ax.set_title(f"Image {idx+1}\nTotal Attention: {total_attention_score:.4f}", fontsize=12)
        ax.axis('off')

    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    # plt.show() # í™”ë©´ì— í‘œì‹œ
    plt.savefig(save_path) # íŒŒì¼ë¡œ ì €ì¥
    # print(f"ê²°ê³¼ê°€ '{save_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


def get_highest_attention_patch_bbox(image_result: dict) -> list:
    """
    per_image ê²°ê³¼ì—ì„œ ì–´í…ì…˜ ìŠ¤ì½”ì–´ê°€ ê°€ì¥ ë†’ì€ íŒ¨ì¹˜ë¥¼ ì°¾ì•„ 
    í•´ë‹¹ íŒ¨ì¹˜ì˜ ì •ê·œí™”ëœ ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        image_result (dict): prediction_results['per_image'] ë¦¬ìŠ¤íŠ¸ì˜ ë‹¨ì¼ ì•„ì´í…œ.

    Returns:
        list: [left, top, right, bottom] í˜•íƒœì˜ ì •ê·œí™”ëœ ì¢Œí‘œ ë¦¬ìŠ¤íŠ¸.
    """
    # 1. ì…ë ¥ ë°ì´í„° ì¶”ì¶œ
    attn_scores = np.array(image_result['attn_scores'][0])
    n_width = image_result['n_width']
    n_height = image_result['n_height']

    # 2. ì–´í…ì…˜ ìŠ¤ì½”ì–´ê°€ ê°€ì¥ ë†’ì€ íŒ¨ì¹˜ì˜ 1ì°¨ì› ì¸ë±ìŠ¤ ì°¾ê¸°
    highest_score_idx = np.argmax(attn_scores)

    # 3. 1ì°¨ì› ì¸ë±ìŠ¤ë¥¼ 2ì°¨ì› íŒ¨ì¹˜ ê·¸ë¦¬ë“œ ì¢Œí‘œ (patch_x, patch_y)ë¡œ ë³€í™˜
    # (patch_xëŠ” ê°€ë¡œ ì¸ë±ìŠ¤, patch_yëŠ” ì„¸ë¡œ ì¸ë±ìŠ¤)
    patch_y = highest_score_idx // n_width
    patch_x = highest_score_idx % n_width

    # 4. íŒ¨ì¹˜ ê·¸ë¦¬ë“œ ì¢Œí‘œë¥¼ ì •ê·œí™”ëœ ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œë¡œ ê³„ì‚°
    # ê° íŒ¨ì¹˜ì˜ ì •ê·œí™”ëœ ë„ˆë¹„ì™€ ë†’ì´
    patch_norm_width = 1.0 / n_width
    patch_norm_height = 1.0 / n_height
    
    # ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚°
    left = patch_x * patch_norm_width
    top = patch_y * patch_norm_height
    right = (patch_x + 1) * patch_norm_width
    bottom = (patch_y + 1) * patch_norm_height
    
    return [left, top, right, bottom]


def visualize_crop(save_dir, gt_bbox, top_q_bboxes, instruction, filename, img_path, click_point=None):
    """Visualize ground truth and selected crop on the image"""
    result_img = Image.open(img_path)

    draw = ImageDraw.Draw(result_img)
    # Draw ground truth bbox in green
    draw.rectangle(gt_bbox, outline="green", width=2)

    font = None
    try:
        font = ImageFont.truetype("DejaVuSans-Bold.ttf", 20)
    except IOError:
        font = ImageFont.load_default()

    for bbox in top_q_bboxes:
        draw.rectangle(bbox, outline="red", width=2)
        text_to_draw = f"{instruction}"
        crop_left, crop_top, crop_right, crop_bottom = bbox
        inst_position = (crop_left, crop_top)
        draw.text(inst_position, text_to_draw, fill="red", font=font)

    # Draw click point as an orange circle
    if click_point is not None:
        click_x, click_y = click_point[0], click_point[1]
        radius = 13
        draw.ellipse((click_x - radius, click_y - radius, click_x + radius, click_y + radius), outline="purple", width=3)

    # Ensure the save directory exists
    os.makedirs(save_dir, exist_ok=True)
    # Save the result image
    result_path = os.path.join(save_dir, filename)
    result_img.save(result_path)


def visualize_attn_map(attn_output, msgs, crop_list, attn_vis_dir, processor, agg_start=20, layer_num=31):
    """Visualize attention maps for crops"""
    image_inputs, _ = process_vision_info(msgs)

    # grid í¬ê¸° ë½‘ì•„ë‘ê¸°
    img_proc_out = processor.image_processor(images=image_inputs)
    grid = img_proc_out["image_grid_thw"]
    # (batch, num_imgs, 3) í˜¹ì€ (num_imgs, 3) í˜•íƒœì¼ ìˆ˜ ìˆìœ¼ë‹ˆ ì•ˆì „í•˜ê²Œ ë½‘ê¸°
    if grid.ndim == 3:
        grid = grid[0]   # (num_imgs, 3)

    # ìµœì¢… token-map ì°¨ì›: t Ã— (h//2) Ã— (w//2)
    final_shapes = [
        (t, h//2, w//2)
        for t, h, w in grid
    ]

    num_imgs = len(crop_list)
    fig, axes = plt.subplots(1, num_imgs, figsize=(5*num_imgs, 5))

    for i, crop in enumerate(crop_list):
        (st, end) = crop["token_span"] # cropì˜ í† í° ì‹œì‘, ë index ë½‘ê¸°
        t, h2, w2 = final_shapes[i]
        att_maps = []

        # for li in range(L):
        for li in range(agg_start, layer_num):
            att = (
                attn_output.attentions[li]         # (batch, heads, seq_q, seq_k)
                [0, :, -1, st:end]              # batch=0, ë§ˆì§€ë§‰ query í† í°, vision span
                .mean(dim=0)                 # head í‰ê· 
                .to(torch.float32)           # bfloat16 â†’ float32
                .cpu()
                .numpy()
            )
            att_map = att.reshape(t, h2, w2).mean(axis=0)  # ì‹œê°„ì¶• í‰ê· 
            att_maps.append(att_map)

        att_avg = np.mean(att_maps, axis=0)  # 32ê°œ ë ˆì´ì–´ í‰ê· 

        ax = axes[i] if num_imgs > 1 else axes
        im = ax.imshow(att_avg, cmap="viridis", interpolation="nearest")
        ax.set_title(f"crop{crop['id']}")
        ax.axis("off")

    plt.tight_layout()

    out_dir = Path(attn_vis_dir)
    out_dir.mkdir(parents=True, exist_ok=True)

    _save_path = os.path.join(out_dir, "attn_map.png")

    fig.savefig(_save_path, dpi=300, bbox_inches="tight", facecolor="white")
    plt.close(fig)


def upsample_att_map(att_map_low_res: np.ndarray, size):
    """
    Pillowë¥¼ ì´ìš©í•œ bilinear ì—…ìƒ˜í”Œ (size=(H, W))
    ì…ë ¥/ì¶œë ¥ ëª¨ë‘ float32 ìœ ì§€
    """
    h, w = size
    # ì•ˆì „ì¥ì¹˜: ìŒìˆ˜/NaN ì œê±°
    m = np.nan_to_num(att_map_low_res.astype(np.float32), nan=0.0, neginf=0.0, posinf=0.0)
    if m.size == 0:
        return np.zeros((h, w), dtype=np.float32)
    # ê°’ ë²”ìœ„ë¥¼ ì¼ë‹¨ 0 ì´ìƒìœ¼ë¡œ í´ë¨í”„
    m[m < 0] = 0.0
    im = Image.fromarray(m)
    im = im.resize((w, h), resample=Image.BILINEAR)
    out = np.array(im).astype(np.float32)
    # scaleì— ë”°ë¼ ê°’ì´ ì•½ê°„ ë³€í•  ìˆ˜ ìˆì–´ 0 ì´ìƒìœ¼ë¡œ ì¬í´ë¨í”„
    out[out < 0] = 0.0
    return out


def boxfilter_sum(arr: np.ndarray, r: int):
    """
    ëë¶€ë¶„ ë³´ì • ì—†ìŒ(neighbor-sum).
    (2r+1)x(2r+1) ì°½ê³¼ ì‹¤ì œ ê²¹ì¹˜ëŠ” ë¶€ë¶„ì˜ 'í•©'ë§Œ ê³„ì‚°.
    í‰ê·  ì•„ë‹˜. ê°€ì¥ìë¦¬ëŠ” ì°½ì´ ëœ ê²¹ì¹˜ë¯€ë¡œ ì†í•´ë³´ê²Œ ë¨.
    """
    if r <= 0:
        return arr.astype(np.float32, copy=True)

    a = arr.astype(np.float32, copy=False)
    H, W = a.shape

    # ì ë¶„ì˜ìƒ: ìƒë‹¨/ì¢Œì¸¡ 0 íŒ¨ë”©ì„ í•œ ì¹¸ ì¶”ê°€í•´ì„œ ë²¡í„°í™” ê³„ì‚° ìš©ì´í•˜ê²Œ êµ¬ì„±
    ii = np.pad(a, ((1, 0), (1, 0)), mode='constant').cumsum(axis=0).cumsum(axis=1)

    ys = np.arange(H)[:, None]   # Hx1
    xs = np.arange(W)[None, :]   # 1xW

    y0 = np.clip(ys - r, 0, H)
    y1 = np.clip(ys + r + 1, 0, H)
    x0 = np.clip(xs - r, 0, W)
    x1 = np.clip(xs + r + 1, 0, W)

    # ì ë¶„ì˜ìƒ ì¸ë±ìŠ¤ëŠ” +1 íŒ¨ë”© ê³ ë ¤í•´ì„œ ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥
    S = ii[y1, x1] - ii[y0, x1] - ii[y1, x0] + ii[y0, x0]
    return S


def visualize_aggregated_attention(
        crop_list,
        original_image, inst_dir, gt_bbox, individual_maps_dir=None,
        neigh_radius = 20,         #! ì´ì›ƒí•©(box filter) ë°˜ê²½ r â†’ (2r+1)^2 ì°½
        topk_points = 5,           # ìƒìœ„ ì  ê°œìˆ˜ (ë³´ì—¬ì£¼ê¸°ìš©)
        min_dist_pix = 200,        # ìƒìœ„ ì  ì‚¬ì´ ìµœì†Œ ê°„ê²© (í”½ì…€)
        star_marker_size= 8,      # ë³„ í¬ê¸° (1ë“±)
        dot_marker_size = 5,      # ì  í¬ê¸° (2~5ë“±)
        text_fontsize= 7          # ì ìˆ˜ í…ìŠ¤íŠ¸ í°íŠ¸ í¬ê¸°
    ):
    """
    ì´ì›ƒí•© ê¸°ë°˜ ìµœëŒ€ì  íƒìƒ‰:
    - í•©ì„± ë§µ ì •ê·œí™” í›„ boxfilter_sum(neigh_radius)ë¡œ ì´ì›ƒí•© ê³„ì‚°
    - greedy ë¹„ìµœëŒ€ ì–µì œ(NMS)ë¡œ ìƒìœ„ topk_points ì¢Œí‘œ ì„ íƒ(ê°„ê²© min_dist_pix)
    - ì‹œê°í™”:
        â€¢ s2_result_only: ì›ë³¸+í•©ì„±ë§µ+GT ë°•ìŠ¤ë§Œ
        â€¢ s2_result_star: top-1ì€ ë³„(*), top-k ëª¨ë‘ëŠ” ì´ì›ƒí•© ì ìˆ˜ í…ìŠ¤íŠ¸ë¡œ í‘œì‹œ
    - ì„±ê³µ íŒì •ì€ top-1 ì ì´ GT ë°•ìŠ¤ ì•ˆì´ë©´ True
    """

    os.makedirs(os.path.dirname(inst_dir + "/stage2"), exist_ok=True)
    if individual_maps_dir:
        os.makedirs(individual_maps_dir, exist_ok=True)

    # ìº”ë²„ìŠ¤ ë° í•©ì„± ë§µ ì¤€ë¹„
    W, H = original_image.size
    aggregated_attention_map = np.zeros((H, W), dtype=np.float32)

    # ê° cropì˜ ë§µì„ ì›ë³¸ ì¢Œí‘œê³„ë¡œ ì—…ìƒ˜í”Œí•˜ì—¬ í•©ì„±
    for crop in crop_list:
        if 'bbox' not in crop or 'att_avg_masked' not in crop:
            continue

        left, top, right, bottom = map(int, crop['bbox'])
        cw = max(0, right - left)
        ch = max(0, bottom - top)
        if cw == 0 or ch == 0:
            continue

        att_low = crop['att_avg_masked']
        att_up = upsample_att_map(att_low, size=(ch, cw))

        # ê°œë³„ ë§µ ì €ì¥(ì˜µì…˜)
        if individual_maps_dir:
            indiv = np.zeros((H, W), dtype=np.float32)
            indiv[top:bottom, left:right] = att_up
            plt.figure(figsize=(10, 10 * H / W))
            plt.imshow(original_image, extent=(0, W, H, 0))
            plt.imshow(indiv, cmap='viridis', alpha=0.6, extent=(0, W, H, 0))
            plt.axis('off')
            ttl = f"Crop ID: {crop.get('id','?')}"
            plt.title(ttl)
            path = os.path.join(individual_maps_dir, f"individual_attn_crop_{crop.get('id','unk')}.png")
            plt.savefig(path, dpi=150, bbox_inches='tight', pad_inches=0)
            plt.close()

        aggregated_attention_map[top:bottom, left:right] += att_up

    # ì´ì›ƒí•© ê¸°ë°˜ ìƒìœ„ ì  ì„ ì •
    top_points = []
    scores = []  # boxfilter_sumìœ¼ë¡œ ì–»ì€ ì´ì›ƒí•© ê°’

    if aggregated_attention_map.max() > 0:
        normalized = aggregated_attention_map / (aggregated_attention_map.max() + 1e-8)
        smoothed = boxfilter_sum(normalized, neigh_radius)

        # greedy NMSë¡œ ìƒìœ„ Kê°œ ì  ì„ íƒ
        sm = smoothed.copy()
        Hh, Ww = sm.shape

        for _ in range(int(topk_points)):
            idx = int(np.argmax(sm))
            vy, vx = divmod(idx, Ww)
            best_val = sm[vy, vx]
            if not np.isfinite(best_val) or best_val <= 0:
                break
            # ì  ê¸°ë¡
            top_points.append((int(vx), int(vy)))
            scores.append(float(best_val))
            # ì •ì‚¬ê°í˜• ì–µì œ
            y1 = max(0, vy - min_dist_pix); y2 = min(Hh - 1, vy + min_dist_pix)
            x1 = max(0, vx - min_dist_pix); x2 = min(Ww - 1, vx + min_dist_pix)
            sm[y1:y2+1, x1:x2+1] = -np.inf

    # ì„±ê³µ íŒì •: top-1 ê¸°ì¤€
    is_grounding_success = False
    if len(top_points) > 0:
        cx, cy = top_points[0]
        gl, gt, gr, gb = gt_bbox
        is_grounding_success = (gl <= cx <= gr) and (gt <= cy <= gb)
        print(f"ğŸ¯ Our Grounding: {(cx, cy)} , GT: {gt_bbox}, Neigh_sum: {scores[0]:.2f}")
    else:
        print("Aggregated attention map empty ë˜ëŠ” peak ì—†ìŒ")

    # ì‹œê°í™”: ê³µí†µ ë°”íƒ•
    fig, ax = plt.subplots(figsize=(10, 10 * H / W))
    ax.imshow(original_image, extent=(0, W, H, 0))
    ax.imshow(aggregated_attention_map, cmap='viridis', alpha=0.6, extent=(0, W, H, 0))

    # ê·¸ëƒ¥ Attention ìƒíƒœë§Œ ì €ì¥ -> ê°€ë¦¬ëŠ”ê±° ì—†ì´ ë³´ì´ë„ë¡.
    plt.savefig(inst_dir + "/s2_result_only.png", dpi=300, bbox_inches="tight", pad_inches=0)

    # GT ë°•ìŠ¤(ì´ˆë¡)
    gl, gt, gr, gb = gt_bbox
    gt_rect = patches.Rectangle((gl, gt), gr - gl, gb - gt, linewidth=3, edgecolor='lime', facecolor='none')
    ax.add_patch(gt_rect)

    # ë²”ë¡€
    green_patch = patches.Patch(color='lime', label='Ground Truth BBox')
    star_legend = Line2D([0], [0], marker='*', color='w', label='NeighSum Top-1', 
                         markerfacecolor='yellow', markeredgecolor='black', markersize=star_marker_size)
    ax.legend([green_patch, star_legend], ['Ground Truth BBox', 'NeighSum Top-1'], loc='best')

    ax.axis('off')
    ax.set_title("Attention (aggregated) + NeighSum Peaks")
    plt.tight_layout()

    # ì‹œê°í™”: top-1 ë³„í‘œ, top-2~5 ê²€ì • ì , top-k í…ìŠ¤íŠ¸ ë¼ë²¨
    if len(top_points) > 0:
        # top-1 ë³„í‘œ
        ax.plot(top_points[0][0], top_points[0][1], 'y*',
                markersize=star_marker_size, markeredgecolor='black')

        # top-2~5 ê²€ì • ì 
        for i in range(1, min(len(top_points), topk_points)):
            px, py = top_points[i]
            ax.plot(px, py, 'o', 
                    markersize=dot_marker_size, markerfacecolor='black', markeredgecolor='white', markeredgewidth=0.9)

        # top-k í…ìŠ¤íŠ¸(ëª¨ë‘ í‘œê¸°: ì ìˆ˜ë§Œ)
        for (px, py), sc in zip(top_points, scores):
            label = f"{sc:.3f}"
            ax.text(px + 10, py - 10, label,
                    fontsize=text_fontsize, color='white', ha='left', va='top',
                    path_effects=[pe.withStroke(linewidth=2, foreground='black')])

    plt.savefig(inst_dir + "/s2_result_star.png", dpi=300, bbox_inches="tight", pad_inches=0)
    plt.close(fig)

    return bool(is_grounding_success)

def _visualize_early_exit_results(crop_list, pred, top_point, gt_bbox, attn_vis_dir, instruction, img_path):
    """Early Exit ì‹œê°í™”"""
    s1_att_vis_path = attn_vis_dir + "/output.png"
    visualize_results(crop_list, pred, instruction=instruction, save_path=s1_att_vis_path)
    
    # ì„ì‹œë¡œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬ (Early Exitì´ë¯€ë¡œ crop selection ì—†ìŒ)
    visualize_crop(save_dir=attn_vis_dir, gt_bbox=gt_bbox, 
                   top_q_bboxes=[], instruction=instruction, filename="ee_gt_vis.png", img_path=img_path,
                    click_point=top_point)


def _visualize_stage1_results(crop_list, pred, attn_vis_dir, instruction):
    """ì¼ë°˜ Stage1 ì‹œê°í™”"""
    s1_att_vis_path = attn_vis_dir + "/output.png"
    visualize_results(crop_list, pred, instruction=instruction, save_path=s1_att_vis_path)


def _visualize_stage2_results(save_dir, crop_list, pred, gt_bbox, click_point, instruction, img_path):
    """Stage 2 ê²°ê³¼ ì‹œê°í™”"""
    s2_att_vis_path = save_dir + "/output.png"
    visualize_results(crop_list, pred, instruction=instruction, save_path=s2_att_vis_path)
    visualize_crop(save_dir=save_dir, gt_bbox=gt_bbox, top_q_bboxes=[], 
                   instruction=instruction, filename="gt_vis.png", click_point=click_point, img_path=img_path)